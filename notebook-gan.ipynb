{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0adcc2737ebf6a4a119f135174df96668767fca1ef1112612db5ecadf2b6d608"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# GAN - MNIST + Keras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0. Necessities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 0.0 Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maths\n",
    "import numpy                                            as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib                                       as mp\n",
    "import matplotlib.pyplot                                as pt\n",
    "\n",
    "# Machine / Deep Learning\n",
    "import tensorflow                                       as tf\n",
    "import keras                                            as ks\n",
    "from keras              import models                   as mls\n",
    "from keras              import layers                   as lys\n",
    "from keras.datasets     import mnist                    as mn\n",
    "from keras.utils        import to_categorical           as tc\n",
    "\n",
    "# Versions\n",
    "print( f\"Numpy .... : {np.__version__}\" )\n",
    "print( f\"Matplotlib : {mp.__version__}\" )\n",
    "print( f\"Tensorflow : {tf.__version__}\" )\n",
    "print( f\"Keras .... : {ks.__version__}\" )"
   ]
  },
  {
   "source": [
    "### 0.1 Class Declaration : MonoGAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoGAN( ks.Model ):\n",
    "    def __init__( self, discriminator, generator, dimension ):\n",
    "        super( MonoGAN, self ).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.dimension = dimension\n",
    "\n",
    "    def compile( self, dr_opt, gr_opt, loss_function ):\n",
    "        super( MonoGAN, self ).compile()\n",
    "        self.dr_opt = dr_opt\n",
    "        self.gr_opt = gr_opt\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train_step( self, real_images ):\n",
    "\n",
    "        if isinstance( real_images, tuple ):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape( real_images )[0]\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator( random_latent_vectors )\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat(\n",
    "            [generated_images, real_images],\n",
    "            axis = 0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones( ( batch_size, 1 ) ), tf.zeros( ( batch_size, 1 ) )],\n",
    "            axis = 0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform( tf.shape( labels ) )\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator( combined_images )\n",
    "            dr_loss = self.loss_function( labels, predictions )\n",
    "        \n",
    "        grads = tape.gradient( dr_loss, self.discriminator.trainable_weights )\n",
    "        self.dr_opt.apply_gradients(\n",
    "            zip( grads, self.discriminator.trainable_weights )\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros( ( batch_size, 1 ) )\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            gr_loss = self.loss_function(misleading_labels, predictions)\n",
    "\n",
    "        grads = tape.gradient( gr_loss, self.generator.trainable_weights )\n",
    "        self.gr_opt.apply_gradients( zip( grads, self.generator.trainable_weights ) )\n",
    "\n",
    "        return {\n",
    "            \"dr_loss\": dr_loss,\n",
    "            \"gr_loss\": gr_loss\n",
    "        }"
   ]
  },
  {
   "source": [
    "### 0.2 Class Declaration : MonoGAN Results Viewer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoGAN_Viewer( ks.callbacks.Callback ):\n",
    "    def __init__( self, image_number = 100, dimension = 128 ):\n",
    "        self.image_number = image_number\n",
    "        self.dimension  = dimension\n",
    "\n",
    "    def on_epoch_end( self, epoch, logs = None ):\n",
    "        random_latent_vectors = tf.random.normal( shape = ( self.image_number, self.dimension ) )\n",
    "        generated_images = self.model.generator( random_latent_vectors )\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range( self.image_number ):\n",
    "            img = ks.preprocessing.image.array_to_img( generated_images[i] )\n",
    "            img.save( \"generated_img_{i}_{epoch}.png\".format( i = i, epoch = epoch ) )"
   ]
  },
  {
   "source": [
    "## 1. Set Up Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.0 Set Up Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up discriminator\n",
    "\n",
    "dr = mls.Sequential( name = \"Discriminator\" )\n",
    "\n",
    "dr.add( lys.Input( shape = ( 28, 28, 1 ) ) )\n",
    "dr.add( lys.Conv2D( 64, ( 3, 3 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "dr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "dr.add( lys.Conv2D( 128, ( 3, 3 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "dr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "dr.add( lys.GlobalMaxPooling2D() )\n",
    "dr.add( lys.Dense( 1 ) )\n",
    "\n",
    "dr.summary()"
   ]
  },
  {
   "source": [
    "### 1.1 Set Up Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 128\n",
    "\n",
    "gr = mls.Sequential( name = \"Generator\" )\n",
    "\n",
    "gr.add( lys.Input( shape = ( dimension, ) ) )\n",
    "gr.add( lys.Dense( 7 * 7 * 128 ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Reshape( ( 7, 7, 128 ) ) )\n",
    "gr.add( lys.Conv2DTranspose( 128, ( 4, 4 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Conv2DTranspose( 128, ( 4, 4 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Conv2DTranspose( 1, ( 7, 7 ), padding = \"same\", activation = \"sigmoid\" ) )\n",
    "\n",
    "gr.summary()"
   ]
  },
  {
   "source": [
    "## 2. Setup MNIST Dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "( tr_images, tr_labels ), ( ts_images, ts_labels ) = mn.load_data()\n",
    "\n",
    "batch_size = 64\n",
    "# partial_size = 100\n",
    "\n",
    "all_digits = np.concatenate( [tr_images, ts_images] )                             # --> Full\n",
    "# all_digits = tr_images[:partial_size]                                             # --> Partial\n",
    "all_digits = all_digits.astype( 'float32' ) / 255\n",
    "all_digits = np.reshape( all_digits, ( -1, 28, 28, 1 ) )\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices( all_digits )\n",
    "dataset = dataset.shuffle( buffer_size=1024 ).batch( batch_size ).prefetch( 32 )"
   ]
  },
  {
   "source": [
    "## 3. Create GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "gan = MonoGAN(\n",
    "    discriminator   = dr,\n",
    "    generator       = gr,\n",
    "    dimension       = dimension\n",
    ")"
   ]
  },
  {
   "source": [
    "## 4.  Compile GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    dr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    gr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    loss_function   = ks.losses.BinaryCrossentropy( from_logits = True )\n",
    ")\n"
   ]
  },
  {
   "source": [
    "## 4. Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.fit(\n",
    "    dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks = [ MonoGAN_Viewer( image_number = 3, dimension = dimension ) ]\n",
    ")"
   ]
  },
  {
   "source": [
    "## 5. Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( 3 ):\n",
    "    pt.subplot( 3, 3, i + 1 )\n",
    "    pt.figure( figsize = ( 30, 30 ) )\n",
    "    im = pt.imread( f\"generated_img_{i}_29.png\" )\n",
    "    pt.imshow( im )"
   ]
  }
 ]
}