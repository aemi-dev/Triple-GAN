{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TripleGAN - MNIST + Keras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0. Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Numpy .... : 1.19.2\nMatplotlib : 3.3.2\nTensorflow : 2.4.0\nTF Addons  : 0.12.0\nKeras .... : 2.4.3\n"
     ]
    }
   ],
   "source": [
    "# Maths\n",
    "import numpy                                            as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib                                       as mp\n",
    "import matplotlib.pyplot                                as pt\n",
    "\n",
    "# Machine / Deep Learning\n",
    "import tensorflow                                       as tf\n",
    "import tensorflow_addons                                as tfa\n",
    "import keras                                            as ks\n",
    "from keras              import models                   as mdls\n",
    "from keras              import layers                   as lyrs\n",
    "from keras.datasets     import mnist                    as mn\n",
    "from keras.utils        import to_categorical           as tc\n",
    "\n",
    "# Versions\n",
    "print( f\"Numpy .... : {np.__version__}\" )\n",
    "print( f\"Matplotlib : {mp.__version__}\" )\n",
    "print( f\"Tensorflow : {tf.__version__}\" )\n",
    "print( f\"TF Addons  : {tfa.__version__}\" )\n",
    "print( f\"Keras .... : {ks.__version__}\" )"
   ]
  },
  {
   "source": [
    "## 1. Set Up Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_shape = ( 28, 28, 1 )\n",
    "classes = 10\n",
    "latent_dim = 100\n",
    "optimizer = tf.optimizers.Adam( 0.0002, 0.5 )\n",
    "losses = ['binary_crossentropy','sparse_categorical_crossentropy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator Constants\n",
    "\n",
    "noise_dis = 0.2\n",
    "alpha_dis = 0.02\n",
    "\n",
    "\n",
    "# Discriminator Functions\n",
    "\n",
    "def lyrs_Noise( ):\n",
    "    return ks.layers.GaussianNoise( stddev = noise_dis )\n",
    "\n",
    "def lyrs_Dense( units, activation = None ):\n",
    "    return ks.layers.Dense( units = units, activation = activation )\n",
    "\n",
    "def lyrs_WeightNorm( x ):\n",
    "    return tfa.layers.WeightNormalization( x )\n",
    "\n",
    "def lyrs_WeightNormDense( units, activation = None ):\n",
    "    return lyrs_WeightNorm( lyrs_Dense( units = units, activation = activation ) )\n",
    "\n",
    "def lyrs_lReLU( ):\n",
    "    return ks.layers.LeakyReLU( alpha = alpha_dis )"
   ]
  },
  {
   "source": [
    "### 1.0 Set Up Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Discriminator\n",
    "\n",
    "dr = mdls.Sequential( name = \"Discriminator\" )\n",
    "\n",
    "dr.add( lyrs.InputLayer( input_shape = ( 28, 28, ) ) )\n",
    "dr.add( lyrs.InputLayer( input_shape = ( 10, ) ) )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 1000 ) )\n",
    "dr.add( lyrs_lReLU() )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 500 ) )\n",
    "dr.add( lyrs_lReLU() )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 250 ) )\n",
    "dr.add( lyrs_lReLU() )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 250 ) )\n",
    "dr.add( lyrs_lReLU() )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 250 ) )\n",
    "dr.add( lyrs_lReLU() )\n",
    "dr.add( lyrs_Noise() )\n",
    "dr.add( lyrs_WeightNormDense( 1, activation = \"sigmoid\" ) )"
   ]
  },
  {
   "source": [
    "### 1.1 Set Up Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Generator\n",
    "\n",
    "gr = mdls.Sequential( name = \"Generator\" )\n",
    "\n",
    "gr.add( lyrs.InputLayer( input_shape = ( latent_dim, 28, 28 ) ) )\n",
    "gr.add( lyrs.Dense( 500, activation = \"softplus\" ) )\n",
    "gr.add( lyrs.BatchNormalization( ) )\n",
    "gr.add( lyrs.Dense( 500, activation = \"softplus\" ) )\n",
    "gr.add( lyrs.BatchNormalization( ) )\n",
    "gr.add( lyrs.Dense( 784, activation = \"sigmoid\" ) )\n",
    "gr.add( lyrs.BatchNormalization( ) )"
   ]
  },
  {
   "source": [
    "### 1.2 Set Up Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Classifier\n",
    "\n",
    "cr = mdls.Sequential( name = \"Classifier\" )\n",
    "\n",
    "cr.add( lyrs.Input( shape = ( latent_dim, 28, 28 ) ) )\n",
    "cr.add( lyrs.Conv2D( 32, kernel_size = ( 5, 5 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lyrs.MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "cr.add( lyrs.Dropout( 0.5 ) )\n",
    "cr.add( lyrs.Conv2D( 64, kernel_size = ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lyrs.Conv2D( 64, kernel_size = ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lyrs.MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "cr.add( lyrs.Dropout( 0.5 ) )\n",
    "cr.add( lyrs.Conv2D( 128, kernel_size = ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lyrs.Conv2D( 128, kernel_size = ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lyrs.GlobalMaxPooling2D() )\n",
    "cr.add( lyrs.Dense( 10, activation = \"softmax\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Discriminator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_6 (InputLayer)         multiple                  0         \n_________________________________________________________________\ngaussian_noise (GaussianNois (None, None, 784)         0         \n_________________________________________________________________\nweight_normalization (Weight (None, None, 1000)        1571001   \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, None, 1000)        0         \n_________________________________________________________________\ngaussian_noise_1 (GaussianNo (None, None, 1000)        0         \n_________________________________________________________________\nweight_normalization_1 (Weig (None, None, 500)         1001501   \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, None, 500)         0         \n_________________________________________________________________\ngaussian_noise_2 (GaussianNo (None, None, 500)         0         \n_________________________________________________________________\nweight_normalization_2 (Weig (None, None, 250)         250751    \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, None, 250)         0         \n_________________________________________________________________\ngaussian_noise_3 (GaussianNo (None, None, 250)         0         \n_________________________________________________________________\nweight_normalization_3 (Weig (None, None, 250)         125751    \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, None, 250)         0         \n_________________________________________________________________\ngaussian_noise_4 (GaussianNo (None, None, 250)         0         \n_________________________________________________________________\nweight_normalization_4 (Weig (None, None, 250)         125751    \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, None, 250)         0         \n_________________________________________________________________\ngaussian_noise_5 (GaussianNo (None, None, 250)         0         \n_________________________________________________________________\nweight_normalization_5 (Weig (None, None, 1)           504       \n=================================================================\nTotal params: 3,075,259\nTrainable params: 1,538,752\nNon-trainable params: 1,536,507\n_________________________________________________________________\nModel: \"Generator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_8 (InputLayer)         multiple                  0         \n_________________________________________________________________\ndense_12 (Dense)             (None, None, 500)         50500     \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, None, 500)         2000      \n_________________________________________________________________\ndense_13 (Dense)             (None, None, 500)         250500    \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, None, 500)         2000      \n_________________________________________________________________\ndense_14 (Dense)             (None, None, 784)         392784    \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, None, 784)         3136      \n=================================================================\nTotal params: 700,920\nTrainable params: 697,352\nNon-trainable params: 3,568\n_________________________________________________________________\nModel: \"Classifier\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_2 (Conv2D)            (None, 100, 28, 32)       22432     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 50, 14, 32)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 50, 14, 32)        0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 50, 14, 64)        18496     \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 50, 14, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 25, 7, 64)         0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 25, 7, 64)         0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 25, 7, 128)        73856     \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 25, 7, 128)        147584    \n_________________________________________________________________\nglobal_max_pooling2d (Global (None, 128)               0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 10)                1290      \n=================================================================\nTotal params: 300,586\nTrainable params: 300,586\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize\n",
    "\n",
    "dr.summary()\n",
    "gr.summary()\n",
    "cr.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleGAN( keras.Model ):\n",
    "    def __init__( self, discriminator, generator, classifier, dimension ):\n",
    "        super( MonoGAN, self ).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.classifier = classifier\n",
    "        self.generator = generator\n",
    "        self.dimension = dimension\n",
    "\n",
    "    def compile( self, dr_opt, gr_opt, loss_function ):\n",
    "        super( MonoGAN, self ).compile()\n",
    "        self.dr_opt = dr_opt\n",
    "        self.gr_opt = gr_opt\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train_step( self, real_images ):\n",
    "\n",
    "        if isinstance( real_images, tuple ):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape( real_images )[0]\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator( random_latent_vectors )\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat(\n",
    "            [generated_images, real_images],\n",
    "            axis = 0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones( ( batch_size, 1 ) ), tf.zeros( ( batch_size, 1 ) )],\n",
    "            axis = 0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform( tf.shape( labels ) )\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator( combined_images )\n",
    "            dr_loss = self.loss_function( labels, predictions )\n",
    "        \n",
    "        grads = tape.gradient( dr_loss, self.discriminator.trainable_weights )\n",
    "        self.dr_opt.apply_gradients(\n",
    "            zip( grads, self.discriminator.trainable_weights )\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros( ( batch_size, 1 ) )\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            gr_loss = self.loss_function(misleading_labels, predictions)\n",
    "\n",
    "        grads = tape.gradient( gr_loss, self.generator.trainable_weights )\n",
    "        self.gr_opt.apply_gradients( zip( grads, self.generator.trainable_weights ) )\n",
    "\n",
    "        return {\n",
    "            \"dr_loss\": dr_loss,\n",
    "            \"gr_loss\": gr_loss\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleGAN_Viewer( ks.callbacks.Callback ):\n",
    "    def __init__( self, image_number = 100, dimension = 128 ):\n",
    "        self.image_number = image_number\n",
    "        self.dimension  = dimension\n",
    "\n",
    "    def on_epoch_end( self, epoch, logs = None ):\n",
    "        random_latent_vectors = tf.random.normal( shape = ( self.image_number, self.dimension ) )\n",
    "        generated_images = self.model.generator( random_latent_vectors )\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range( self.image_number ):\n",
    "            img = ks.preprocessing.image.array_to_img( generated_images[i] )\n",
    "            img.save( \"generated_img_{i}_{epoch}.png\".format( i = i, epoch = epoch ) )\n"
   ]
  },
  {
   "source": [
    "## 2. Setup MNIST Dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "( tr_images, tr_labels ), ( ts_images, ts_labels ) = mn.load_data()\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "#all_digits = np.concatenate( [tr_images, ts_images] )\n",
    "all_digits = tr_images[:100]\n",
    "all_digits = ( all_digits.astype( 'float32' ) - 127.5 ) / 127.5\n",
    "all_digits = np.reshape( all_digits, ( -1, 28, 28, 1 ) )\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices( all_digits )\n",
    "dataset = dataset.shuffle( buffer_size=1024 ).batch( batch_size ).prefetch( 32 )"
   ]
  },
  {
   "source": [
    "## 3. Create GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "gan = MonoGAN(\n",
    "    discriminator   = dr,\n",
    "    generator       = gr,\n",
    "    dimension       = dimension\n",
    ")"
   ]
  },
  {
   "source": [
    "## 4.  Compile GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    dr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    gr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    loss_function   = ks.losses.BinaryCrossentropy( from_logits = True )\n",
    ")\n"
   ]
  },
  {
   "source": [
    "## 4. Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 66s 69ms/step - loss: 0.8713 - accuracy: 0.8633\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.0243 - accuracy: 0.9948\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 41s 43ms/step - loss: 0.0150 - accuracy: 0.9967\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.0168 - accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.0163 - accuracy: 0.9964\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149e3b0a0>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "gan.fit(\n",
    "    dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks = [ MonoGAN_Monitor( image_number = 3, dimension = dimension ) ]\n",
    ")"
   ]
  },
  {
   "source": [
    "## 5. Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0508 - accuracy: 0.9910\n",
      "0.9909999966621399\n"
     ]
    }
   ],
   "source": [
    "for i in range( 3 ):\n",
    "    pt.figure( figsize = ( 30, 30 ) )\n",
    "    im = pt.imread( f\"./generated_img_{i}_29.png\" )\n",
    "    pt.imshow( im )"
   ]
  }
 ]
}