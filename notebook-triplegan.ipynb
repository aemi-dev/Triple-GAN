{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# TripleGAN - MNIST + Keras"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 0. Necessities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 0.0 Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'Onehot' from 'keras.preprocessing' (/Library/Python/3.8/site-packages/keras/preprocessing/__init__.py)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-184ff56de3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mmnist\u001b[0m                    \u001b[0;32mas\u001b[0m \u001b[0mmn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m        \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m           \u001b[0;32mas\u001b[0m \u001b[0mtc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnehot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Custom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Onehot' from 'keras.preprocessing' (/Library/Python/3.8/site-packages/keras/preprocessing/__init__.py)"
     ]
    }
   ],
   "source": [
    "# Maths\n",
    "import numpy                                            as np\n",
    "\n",
    "# Matplotlib\n",
    "import matplotlib                                       as mp\n",
    "import matplotlib.pyplot                                as pt\n",
    "\n",
    "# Machine / Deep Learning\n",
    "import tensorflow                                       as tf\n",
    "import keras                                            as ks\n",
    "from keras              import models                   as mls\n",
    "from keras              import layers                   as lys\n",
    "from keras.datasets     import mnist                    as mn\n",
    "from keras.utils        import to_categorical           as tc\n",
    "\n",
    "# Versions\n",
    "print( f\"Numpy .... : {np.__version__}\" )\n",
    "print( f\"Matplotlib : {mp.__version__}\" )\n",
    "print( f\"Tensorflow : {tf.__version__}\" )\n",
    "print( f\"Keras .... : {ks.__version__}\" )"
   ]
  },
  {
   "source": [
    "### 0.1 Class Declaration : TripleGAN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleGAN( ks.Model ):\n",
    "    def __init__( self, discriminator, generator, classifier, dimension ):\n",
    "        super( TripleGAN, self ).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.classifier = classifier\n",
    "        self.generator = generator\n",
    "        self.dimension = dimension\n",
    "\n",
    "    def compile( self, dr_opt, gr_opt, cr_opt, loss_function ):\n",
    "        super( TripleGAN, self ).compile()\n",
    "        self.dr_opt = dr_opt\n",
    "        self.gr_opt = gr_opt\n",
    "        self.cr_opt = cr_opt\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train_step( self, real_images ):\n",
    "\n",
    "        if isinstance( real_images, tuple ):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        batch_size = tf.shape( real_images )[0]\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Decode them to fake images\n",
    "        generated_images = self.generator( random_latent_vectors )\n",
    "\n",
    "        # Combine them with real images\n",
    "        combined_images = tf.concat(\n",
    "            [generated_images, real_images],\n",
    "            axis = 0\n",
    "        )\n",
    "\n",
    "        # Assemble labels discriminating real from fake images\n",
    "        labels = tf.concat(\n",
    "            [tf.ones( ( batch_size, 1 ) ), tf.zeros( ( batch_size, 1 ) )],\n",
    "            axis = 0\n",
    "        )\n",
    "        # Add random noise to the labels - important trick!\n",
    "        labels += 0.05 * tf.random.uniform( tf.shape( labels ) )\n",
    "\n",
    "        # Train the discriminator\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator( combined_images )\n",
    "            dr_loss = self.loss_function( labels, predictions )\n",
    "        \n",
    "        grads = tape.gradient( dr_loss, self.discriminator.trainable_weights )\n",
    "        self.dr_opt.apply_gradients(\n",
    "            zip( grads, self.discriminator.trainable_weights )\n",
    "        )\n",
    "\n",
    "        # Sample random points in the latent space\n",
    "        random_latent_vectors = tf.random.normal( shape = ( batch_size, self.dimension ) )\n",
    "\n",
    "        # Assemble labels that say \"all real images\"\n",
    "        misleading_labels = tf.zeros( ( batch_size, 1 ) )\n",
    "\n",
    "        # Train the generator (note that we should *not* update the weights\n",
    "        # of the discriminator)!\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            gr_loss = self.loss_function(misleading_labels, predictions)\n",
    "\n",
    "        grads = tape.gradient( gr_loss, self.generator.trainable_weights )\n",
    "        self.gr_opt.apply_gradients( zip( grads, self.generator.trainable_weights ) )\n",
    "\n",
    "        return {\n",
    "            \"dr_loss\": dr_loss,\n",
    "            \"gr_loss\": gr_loss\n",
    "        }\n"
   ]
  },
  {
   "source": [
    "### 0.2 Class Declaration : TripleGAN_Viewer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ERRONEOUS\n",
    "\n",
    "class TripleGAN_Viewer( ks.callbacks.Callback ):\n",
    "    def __init__( self, image_number = 100, dimension = 128 ):\n",
    "        self.image_number = image_number\n",
    "        self.dimension  = dimension\n",
    "\n",
    "    def on_epoch_end( self, epoch, logs = None ):\n",
    "        random_latent_vectors = tf.random.normal( shape = ( self.image_number, self.dimension ) )\n",
    "        generated_images = self.model.generator( random_latent_vectors )\n",
    "        generated_images *= 255\n",
    "        generated_images.numpy()\n",
    "        for i in range( self.image_number ):\n",
    "            img = ks.preprocessing.image.array_to_img( generated_images[i] )\n",
    "            img.save( \"generated_img_{i}_{epoch}.png\".format( i = i, epoch = epoch ) )"
   ]
  },
  {
   "source": [
    "## 1. Set Up Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 1.0 Set Up Discriminator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Discriminator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_13 (Dense)             (None, 1000)              11000     \n_________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)   (None, 1000)              0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 500)               500500    \n_________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)   (None, 500)               0         \n_________________________________________________________________\ndense_15 (Dense)             (None, 250)               125250    \n_________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)   (None, 250)               0         \n_________________________________________________________________\ndense_16 (Dense)             (None, 250)               62750     \n_________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)   (None, 250)               0         \n_________________________________________________________________\ndense_17 (Dense)             (None, 250)               62750     \n_________________________________________________________________\nleaky_re_lu_16 (LeakyReLU)   (None, 250)               0         \n_________________________________________________________________\ndense_18 (Dense)             (None, 1)                 251       \n=================================================================\nTotal params: 762,501\nTrainable params: 762,501\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up discriminator\n",
    "\n",
    "\n",
    "\n",
    "dr = mls.Sequential( name = \"Discriminator\" )\n",
    "\n",
    "dr.add( lys.Input( shape = ( 10, ) ) )\n",
    "dr.add( lys.Dense( 1000 ) )\n",
    "dr.add( lys.LeakyReLU() )\n",
    "dr.add( lys.Dense( 500 ) )\n",
    "dr.add( lys.LeakyReLU() )\n",
    "dr.add( lys.Dense( 250 ) )\n",
    "dr.add( lys.LeakyReLU() )\n",
    "dr.add( lys.Dense( 250 ) )\n",
    "dr.add( lys.LeakyReLU() )\n",
    "dr.add( lys.Dense( 250 ) )\n",
    "dr.add( lys.LeakyReLU() )\n",
    "dr.add( lys.Dense( 1, activation = \"sigmoid\" ) )\n",
    "\n",
    "dr.summary()"
   ]
  },
  {
   "source": [
    "### 1.1 Set Up Generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Generator\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_3 (Dense)              (None, 6272)              809088    \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 6272)              0         \n_________________________________________________________________\nreshape (Reshape)            (None, 7, 7, 128)         0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 14, 14, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_5 (LeakyReLU)    (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 28, 28, 128)       262272    \n_________________________________________________________________\nleaky_re_lu_6 (LeakyReLU)    (None, 28, 28, 128)       0         \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 28, 28, 1)         6273      \n=================================================================\nTotal params: 1,339,905\nTrainable params: 1,339,905\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dimension = 128\n",
    "\n",
    "gr = mls.Sequential( name = \"Generator\" )\n",
    "\n",
    "gr.add( lys.Input( shape = ( dimension, ) ) )\n",
    "gr.add( lys.Dense( 7 * 7 * 128 ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Reshape( ( 7, 7, 128 ) ) )\n",
    "gr.add( lys.Conv2DTranspose( 128, ( 4, 4 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Conv2DTranspose( 128, ( 4, 4 ), strides = ( 2, 2 ), padding = \"same\" ) )\n",
    "gr.add( lys.LeakyReLU( alpha = 0.2 ) )\n",
    "gr.add( lys.Conv2DTranspose( 1, ( 7, 7 ), padding = \"same\", activation = \"sigmoid\" ) )\n",
    "\n",
    "gr.summary()"
   ]
  },
  {
   "source": [
    "### 1.2 Set Up Classifier"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"Classifier\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_23 (Conv2D)           (None, 128, 28, 32)       22432     \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 64, 14, 32)        0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 64, 14, 32)        0         \n_________________________________________________________________\nconv2d_24 (Conv2D)           (None, 64, 14, 64)        18496     \n_________________________________________________________________\nconv2d_25 (Conv2D)           (None, 64, 14, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_8 (MaxPooling2 (None, 32, 7, 64)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32, 7, 64)         0         \n_________________________________________________________________\nconv2d_26 (Conv2D)           (None, 32, 7, 128)        73856     \n_________________________________________________________________\nconv2d_27 (Conv2D)           (None, 32, 7, 128)        147584    \n_________________________________________________________________\nglobal_max_pooling2d_4 (Glob (None, 128)               0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 10)                1290      \n=================================================================\nTotal params: 300,586\nTrainable params: 300,586\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cr = mls.Sequential( name = \"Classifier\" )\n",
    "\n",
    "cr.add( lys.Input( shape = ( dimension, 28, 28 ) ) )\n",
    "cr.add( lys.Conv2D( 32, ( 5, 5 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lys.MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "cr.add( lys.Dropout( 0.5 ) )\n",
    "cr.add( lys.Conv2D( 64, ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lys.Conv2D( 64, ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lys.MaxPooling2D( pool_size = ( 2, 2 ) ) )\n",
    "cr.add( lys.Dropout( 0.5 ) )\n",
    "cr.add( lys.Conv2D( 128, ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lys.Conv2D( 128, ( 3, 3 ), activation = \"relu\", padding = \"same\" ) )\n",
    "cr.add( lys.GlobalMaxPooling2D() )\n",
    "cr.add( lys.Dense( 10, activation = \"softmax\" ) )\n",
    "\n",
    "cr.summary()"
   ]
  },
  {
   "source": [
    "## 2. Setup MNIST Dataset "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "( tr_images, tr_labels ), ( ts_images, ts_labels ) = mn.load_data()\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "all_digits = np.concatenate( [tr_images, ts_images] )\n",
    "all_digits = all_digits.astype( 'float32' ) / 255\n",
    "all_digits = np.reshape( all_digits, ( -1, 28, 28, 1 ) )\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices( all_digits )\n",
    "dataset = dataset.shuffle( buffer_size=1024 ).batch( batch_size ).prefetch( 32 )"
   ]
  },
  {
   "source": [
    "## 3. Create GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "\n",
    "gan = MonoGAN(\n",
    "    discriminator   = dr,\n",
    "    generator       = gr,\n",
    "    dimension       = dimension\n",
    ")"
   ]
  },
  {
   "source": [
    "## 4.  Compile GAN Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(\n",
    "    dr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    gr_opt          = ks.optimizers.Adam( learning_rate = 0.0003 ),\n",
    "    loss_function   = ks.losses.BinaryCrossentropy( from_logits = True )\n",
    ")\n"
   ]
  },
  {
   "source": [
    "## 4. Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 66s 69ms/step - loss: 0.8713 - accuracy: 0.8633\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 60s 64ms/step - loss: 0.0243 - accuracy: 0.9948\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 41s 43ms/step - loss: 0.0150 - accuracy: 0.9967\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.0168 - accuracy: 0.9961\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 44s 47ms/step - loss: 0.0163 - accuracy: 0.9964\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x149e3b0a0>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "gan.fit(\n",
    "    dataset,\n",
    "    epochs = epochs,\n",
    "    callbacks = [ MonoGAN_Monitor( image_number = 3, dimension = dimension ) ]\n",
    ")"
   ]
  },
  {
   "source": [
    "## 5. Evaluate Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "313/313 [==============================] - 2s 8ms/step - loss: 0.0508 - accuracy: 0.9910\n",
      "0.9909999966621399\n"
     ]
    }
   ],
   "source": [
    "for i in range( 3 ):\n",
    "    pt.figure( figsize = ( 30, 30 ) )\n",
    "    im = pt.imread( f\"./generated_img_{i}_29.png\" )\n",
    "    pt.imshow( im )"
   ]
  }
 ]
}